{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Clustering4Ever](https://github.com/Clustering4Ever/Clustering4Ever) by [LIPN](https://lipn.univ-paris13.fr/) [A3](https://lipn.univ-paris13.fr/accueil/equipe/a3/) team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%classpath add mvn\n",
    "org.clustering4ever clustering4ever_2.11 0.9.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "787faf80-ef0e-4a2e-b05c-e291509e3e82",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%classpath add mvn org.apache.spark spark-sql_2.11 2.2.1\n",
    "org.apache.log4j.Logger.getRootLogger().setLevel(org.apache.log4j.Level.ERROR);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "org.apache.spark.SparkContext@681c52ca"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "\n",
    "val spark = SparkSession.builder()\n",
    "                        .appName(\"Simple Application\")\n",
    "                        .master(\"local[4]\")\n",
    "                        .config(\"spark.ui.enabled\", \"false\")\n",
    "                        .getOrCreate()\n",
    "val sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import scala.collection.mutable\n",
       "import org.clustering4ever.math.distances.scalar.{Euclidean, Cosine, Minkowski}\n",
       "import org.clustering4ever.math.distances.ContinuousDistance\n",
       "import org.clustering4ever.clustering.epsilonproximity.rdd.EpsilonProximityScalar\n",
       "import org.clustering4ever.vectorizables.Vectorizable\n",
       "import org.clustering4ever.clusterizables.EasyClusterizable\n",
       "import org.apache.spark.storage.StorageLevel\n",
       "import org.clustering4ever.vectors.ScalarVector\n",
       "import org.clustering4ever.hashing.LDLSH\n",
       "import org.clustering4ever.spark.clustering.GradientAscent\n",
       "import org.clustering4ever.shapeless.{VMapping, VectorizationMapping}\n",
       "import org.clustering4ever.clustering.indices.MultiExternalIndicesLocal\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scala.collection.mutable\n",
    "import org.clustering4ever.math.distances.scalar.{Euclidean, Cosine, Minkowski}\n",
    "import org.clustering4ever.math.distances.ContinuousDistance\n",
    "import org.clustering4ever.clustering.epsilonproximity.rdd.EpsilonProximityScalar\n",
    "import org.clustering4ever.vectorizables.Vectorizable\n",
    "import org.clustering4ever.clusterizables.EasyClusterizable\n",
    "import org.apache.spark.storage.StorageLevel\n",
    "import org.clustering4ever.vectors.ScalarVector\n",
    "import org.clustering4ever.hashing.LDLSH\n",
    "import org.clustering4ever.spark.clustering.GradientAscent\n",
    "import org.clustering4ever.shapeless.{VMapping, VectorizationMapping}\n",
    "import org.clustering4ever.clustering.indices.MultiExternalIndicesLocal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download dataset Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-08-23 11:37:40--  http://www.clustering4ever.org/Datasets/DS1/DS1.csv\n",
      "Résolution de www.clustering4ever.org (www.clustering4ever.org)… 62.210.16.62\n",
      "Connexion à www.clustering4ever.org (www.clustering4ever.org)|62.210.16.62|:80… connecté.\n",
      "requête HTTP transmise, en attente de la réponse… 200 OK\n",
      "Taille : 73786 (72K) [text/csv]\n",
      "Sauvegarde en : « /tmp/DS1.csv.1 »\n",
      "\n",
      "     0K .......... .......... .......... .......... .......... 69%  744K 0s\n",
      "    50K .......... .......... ..                              100%  662K=0,1s\n",
      "\n",
      "2019-08-23 11:37:40 (717 KB/s) — « /tmp/DS1.csv.1 » sauvegardé [73786/73786]\n",
      "\n",
      "--2019-08-23 11:37:40--  http://www.clustering4ever.org/Datasets/DS1/DS1-labels.csv\n",
      "Résolution de www.clustering4ever.org (www.clustering4ever.org)… 62.210.16.62\n",
      "Connexion à www.clustering4ever.org (www.clustering4ever.org)|62.210.16.62|:80… connecté.\n",
      "requête HTTP transmise, en attente de la réponse… 200 OK\n",
      "Taille : 19315 (19K) [text/csv]\n",
      "Sauvegarde en : « /tmp/DS1-labels.csv.1 »\n",
      "\n",
      "     0K .......... ........                                   100%  359K=0,05s\n",
      "\n",
      "2019-08-23 11:37:41 (359 KB/s) — « /tmp/DS1-labels.csv.1 » sauvegardé [19315/19315]\n",
      "\n",
      "--2019-08-23 11:37:41--  http://www.clustering4ever.org/Datasets/Aggregation/aggregation.csv\n",
      "Résolution de www.clustering4ever.org (www.clustering4ever.org)… 62.210.16.62\n",
      "Connexion à www.clustering4ever.org (www.clustering4ever.org)|62.210.16.62|:80… connecté.\n",
      "requête HTTP transmise, en attente de la réponse… 200 OK\n",
      "Taille : 8063 (7,9K) [text/csv]\n",
      "Sauvegarde en : « /tmp/aggregation.csv.1 »\n",
      "\n",
      "     0K .......                                               100%  338K=0,02s\n",
      "\n",
      "2019-08-23 11:37:41 (338 KB/s) — « /tmp/aggregation.csv.1 » sauvegardé [8063/8063]\n",
      "\n",
      "--2019-08-23 11:37:41--  http://www.clustering4ever.org/Datasets/Aggregation/labels\n",
      "Résolution de www.clustering4ever.org (www.clustering4ever.org)… 62.210.16.62\n",
      "Connexion à www.clustering4ever.org (www.clustering4ever.org)|62.210.16.62|:80… connecté.\n",
      "requête HTTP transmise, en attente de la réponse… 200 OK\n",
      "Taille : 1576 (1,5K)\n",
      "Sauvegarde en : « /tmp/labels.1 »\n",
      "\n",
      "     0K .                                                     100% 95,5K=0,02s\n",
      "\n",
      "2019-08-23 11:37:51 (95,5 KB/s) — « /tmp/labels.1 » sauvegardé [1576/1576]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "wget -P /tmp/ http://www.clustering4ever.org/Datasets/DS1/DS1.csv\n",
    "wget -P /tmp/ http://www.clustering4ever.org/Datasets/DS1/DS1-labels.csv\n",
    "wget -P /tmp/ http://www.clustering4ever.org/Datasets/Aggregation/aggregation.csv\n",
    "wget -P /tmp/ http://www.clustering4ever.org/Datasets/Aggregation/labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val path = \"/tmp/aggregation.csv\"\n",
    "val data = scala.io.Source.fromFile(path).getLines.map( x => Array(x.split(\",\").map(_.toDouble):_*) ).zipWithIndex\n",
    "  .map{ case (v, id) => EasyClusterizable(id.toLong, ScalarVector(v)) }.toSeq\n",
    "val rdd = sc.parallelize(data)\n",
    "val labelsPath = \"/tmp/labels\"\n",
    "val labels = scala.io.Source.fromFile(labelsPath).getLines.toSeq.map(_.toInt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Ascent parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LDLSH(2,1.0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val k = 80 // Main Gradient Ascent parameter, the k of knn gradient ascent\n",
    "val k2 = 1 // Optional parameter which determine if studied point has to switch to its knn majority vote neighbor bucket\n",
    "val epsilon = 0.01 // Stopping criteria for Gradient Ascent, every point have to moove less than epsilon in order to stop iteration\n",
    "val maxNumberIter = 20 \n",
    "val bucketLayers = 1 // Neighbor bucket layer take into account during Gradient Ascent, at least 1 is recommended for decent k values, the bigger it is the slower it become\n",
    "val w = 1D // Don't observe any change by changing this value, let it to whatever you want\n",
    "val bucketNumber = 8 // Approximatively DS_Size / 1000 for decent performance, the large buckets are the slower it becomes\n",
    "val propConvStopIter = 1D // Supplementary stopping criteria, stop if propConvStopIter % of data have converged\n",
    "val memoryExpensive = true // Choose for fast or slow computation at some memory cost (building of similarity matrix per bucket per iter or on the fly (more calculus))\n",
    "val persistanceLVL: StorageLevel = StorageLevel.MEMORY_ONLY // Persistance Spark level \n",
    "val dim = 2 // Dim of your dataset\n",
    "val lsh = LDLSH(dim, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Epsilon proximity parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Main parameter epsilon can be approximate with average distance knn => \"knn:88\" or be expressed directly as a double \"eps:3.67\"\n",
    "val epsilonEpsProx = \"knn:40\"\n",
    "// val epsilonEpsProx = \"eps:2.56\"\n",
    "val classicalMetric = Euclidean(false)\n",
    "val bucketNumber = 8 // Number of buckets in LSH, Approximatively DS_Size / 1000 for decent performance, the large buckets are the slower it becomes\n",
    "val bucketLayers = 1 // Neighbor bucket layer take into account during Gradient Ascent, at least 1 is recommended for decent k values, the bigger it is the slower it become\n",
    "val methodChoice = \"bydot:1\" // Fusionning cluster methods, at least X dot have to satisfy fusionning condition with \"bydot:X\", X=1 is greatly recommended\n",
    "val divisionFactor = 1 // Experimental, let it to 1, it is supposed to speedup process on large datasets with bigger values but doesn't affect results\n",
    "val cmin = 0 // Fusion clusters that have less than X elements with their closest cluster, it is in O(c²) with c number of clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "<console>",
     "evalue": "134",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m<console>:134: error: type mismatch;\u001b[0;0m",
      "\u001b[1;31m found   : org.clustering4ever.shapeless.VMapping.type\u001b[0;0m",
      "\u001b[1;31m required: org.clustering4ever.shapeless.VMapping[org.clustering4ever.types.VectorizationIDTypes.VectorizationID,?]\u001b[0;0m",
      "\u001b[1;31m    (which expands to)  org.clustering4ever.shapeless.VMapping[Int,?]\u001b[0;0m",
      "\u001b[1;31m       val updatedData = ascended.map( cz => cz.addAlternativeVector(idOriginalVector, cz.v).switchForExistingVectorization(idToStoreGAVector, vm) )\u001b[0;0m",
      "\u001b[1;31m                                                                                                                                               ^\u001b[0;0m",
      "\u001b[1;31m<console>:146: error: type mismatch;\u001b[0;0m",
      "\u001b[1;31m found   : org.apache.spark.rdd.RDD[Nothing]\u001b[0;0m",
      "\u001b[1;31m required: org.apache.spark.rdd.RDD[Cz[O,org.clustering4ever.vectors.ScalarVector]]\u001b[0;0m",
      "\u001b[1;31mNote: Nothing <: Cz[O,org.clustering4ever.vectors.ScalarVector], but class RDD is invariant in type T.\u001b[0;0m",
      "\u001b[1;31mYou may wish to define T as +T instead. (SLS 4.5)\u001b[0;0m",
      "\u001b[1;31m       ).fit(updatedData)\u001b[0;0m",
      "\u001b[1;31m             ^\u001b[0;0m",
      "\u001b[1;31m<console>:148: error: type mismatch;\u001b[0;0m",
      "\u001b[1;31m found   : org.apache.spark.rdd.RDD[Nothing]\u001b[0;0m",
      "\u001b[1;31m required: org.apache.spark.rdd.RDD[Cz[O,org.clustering4ever.vectors.ScalarVector]]\u001b[0;0m",
      "\u001b[1;31mNote: Nothing <: Cz[O,org.clustering4ever.vectors.ScalarVector], but class RDD is invariant in type T.\u001b[0;0m",
      "\u001b[1;31mYou may wish to define T as +T instead. (SLS 4.5)\u001b[0;0m",
      "\u001b[1;31m       val clusterizedRDD = model.obtainInputDataClustering(updatedData)\u001b[0;0m",
      "\u001b[1;31m                                                            ^\u001b[0;0m",
      "\u001b[1;31m<console>:150: error: value clusterIDs is not a member of Nothing\u001b[0;0m",
      "\u001b[1;31m       val predLabels = clusterizedRDD.map(_.clusterIDs.head).collect\u001b[0;0m",
      "\u001b[1;31m                                             ^\u001b[0;0m",
      "\u001b[1;31m<console>:155: error: type mismatch;\u001b[0;0m",
      "\u001b[1;31m found   : Array[Nothing]\u001b[0;0m",
      "\u001b[1;31m required: scala.collection.GenIterable[?]\u001b[0;0m",
      "\u001b[1;31m       val targetAndPred = trueLabels.zip(predLabels)\u001b[0;0m",
      "\u001b[1;31m                                          ^\u001b[0;0m"
     ]
    }
   ],
   "source": [
    "// Theses 3 params have to be here else there is some bugs..., it works more properly on full programm versions\n",
    "val idOriginalVector = 8\n",
    "val idToStoreGAVector = 0\n",
    "val vm = VMapping\n",
    "\n",
    "val t0 = System.currentTimeMillis\n",
    "\n",
    "val ascended = GradientAscent.train(rdd, k, epsilon, maxNumberIter, bucketNumber, bucketLayers, k2, propConvStopIter, memoryExpensive,\n",
    "  persistanceLVL, idToStoreGAVector, true)\n",
    "\n",
    "\n",
    "val updatedData = ascended.map( cz => cz.addAlternativeVector(idOriginalVector, cz.v).switchForExistingVectorization(idToStoreGAVector, vm) )\n",
    "\n",
    "val model = EpsilonProximityScalar(\n",
    "  epsilonEpsProx,\n",
    "  methodChoice,\n",
    "  classicalMetric,\n",
    "  bucketNumber,\n",
    "  lsh,\n",
    "  cmin,\n",
    "  bucketLayers,\n",
    "  StorageLevel.MEMORY_ONLY,\n",
    "  divisionFactor\n",
    ").fit(updatedData)\n",
    "\n",
    "val clusterizedRDD = model.obtainInputDataClustering(updatedData)\n",
    "\n",
    "val predLabels = clusterizedRDD.map(_.clusterIDs.head).collect\n",
    "\n",
    "val t1 = System.currentTimeMillis\n",
    "\n",
    "val trueLabels = scala.io.Source.fromFile(labelsPath).getLines.map(_.toInt).toSeq.toArray\n",
    "val targetAndPred = trueLabels.zip(predLabels)\n",
    "\n",
    "(t1 - t0) / 1000D"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "",
   "name": "Scala",
   "nbconverter_exporter": "",
   "version": "2.11.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
