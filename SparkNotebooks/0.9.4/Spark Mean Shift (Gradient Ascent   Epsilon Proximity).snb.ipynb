{
  "metadata" : {
    "id" : "1793fab8-0652-4f8f-9baf-9745f64926f1",
    "name" : "Spark Mean Shift (Gradient Ascent + Epsilon Proximity)",
    "user_save_timestamp" : "1970-01-01T01:00:00.000Z",
    "auto_save_timestamp" : "1970-01-01T01:00:00.000Z",
    "language_info" : {
      "name" : "scala",
      "file_extension" : "scala",
      "codemirror_mode" : "text/x-scala"
    },
    "trusted" : true,
    "sparkNotebook" : null,
    "customLocalRepo" : "${HOME}/.ivy2",
    "customRepos" : null,
    "customDeps" : [
      "com.github.haifengl:smile-scala_2.11:1.5.0",
      "org.apache.sanselan % sanselan % 0.97-incubator",
      "org.clustering4ever %% clustering4ever % 0.9.4"
    ],
    "customImports" : null,
    "customArgs" : null,
    "customSparkConf" : {
      "spark.master" : "local[8]",
      "spark.executor.memory" : "20G"
    },
    "customVars" : null
  },
  "cells" : [
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "2913C6A4850E42208AF6EA72EDF85972"
      },
      "cell_type" : "code",
      "source" : [
        "import scala.collection.mutable\n",
        "import smile.plot._\n",
        "import org.clustering4ever.math.distances.scalar.{Euclidean, Cosine, Minkowski}\n",
        "import org.clustering4ever.math.distances.ContinuousDistance\n",
        "import org.clustering4ever.clustering.epsilonproximity.rdd.EpsilonProximityScalar\n",
        "import org.clustering4ever.vectorizables.Vectorizable\n",
        "import org.clustering4ever.clusterizables.EasyClusterizable\n",
        "import org.apache.spark.storage.StorageLevel\n",
        "import org.clustering4ever.vectors.ScalarVector\n",
        "import org.clustering4ever.hashing.LDLSH\n",
        "import org.clustering4ever.spark.clustering.GradientAscent\n",
        "import org.clustering4ever.shapeless.{VMapping, VectorizationMapping}\n",
        "import org.clustering4ever.clustering.indices.MultiExternalIndicesLocal"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "import scala.collection.mutable\nimport smile.plot._\nimport org.clustering4ever.math.distances.scalar.{Euclidean, Cosine, Minkowski}\nimport org.clustering4ever.math.distances.ContinuousDistance\nimport org.clustering4ever.clustering.epsilonproximity.rdd.EpsilonProximityScalar\nimport org.clustering4ever.vectorizables.Vectorizable\nimport org.clustering4ever.clusterizables.EasyClusterizable\nimport org.apache.spark.storage.StorageLevel\nimport org.clustering4ever.vectors.ScalarVector\nimport org.clustering4ever.hashing.LDLSH\nimport org.clustering4ever.spark.clustering.GradientAscent\nimport org.clustering4ever.shapeless.{VMapping, VectorizationMapping}\nimport org.clustering4ever.clustering.indices.MultiExternalIndicesLocal\n"
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : ""
          },
          "output_type" : "execute_result",
          "execution_count" : 2,
          "time" : "Took: 0.996s, at 2019-05-09 11:14"
        }
      ]
    },
    {
      "metadata" : {
        "id" : "456D45C45FBE4580973689E4AEF875EE"
      },
      "cell_type" : "markdown",
      "source" : "## Download dataset Aggregation"
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "2B9DAA1A1D6E4BD59907AC8CDD3FA54D"
      },
      "cell_type" : "code",
      "source" : [
        ":sh wget -P /tmp/ http://www.clustering4ever.org/Datasets/DS1/DS1.csv\n",
        ":sh wget -P /tmp/ http://www.clustering4ever.org/Datasets/DS1/DS1-labels.csv\n",
        ":sh wget -P /tmp/ http://www.clustering4ever.org/Datasets/Aggregation/aggregation.csv\n",
        ":sh wget -P /tmp/ http://www.clustering4ever.org/Datasets/Aggregation/labels"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "--2019-05-09 11:14:33--  http://www.clustering4ever.org/Datasets/DS1/DS1.csv\nResolving www.clustering4ever.org (www.clustering4ever.org)... 62.210.16.62\nConnecting to www.clustering4ever.org (www.clustering4ever.org)|62.210.16.62|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 73786 (72K) [text/csv]\nSaving to: ‘/tmp/DS1.csv.3’\n\n     0K .......... .......... .......... .......... .......... 69%  238K 0s\n    50K .......... .......... ..                              100%  102K=0.4s\n\n2019-05-09 11:14:33 (169 KB/s) - ‘/tmp/DS1.csv.3’ saved [73786/73786]\n\n:sh: Scheme missing.\n--2019-05-09 11:14:33--  http://wget/\nResolving wget (wget)... failed: Name or service not known.\nwget: unable to resolve host address ‘wget’\n--2019-05-09 11:14:33--  http://www.clustering4ever.org/Datasets/DS1/DS1-labels.csv\nReusing existing connection to www.clustering4ever.org:80.\nHTTP request sent, awaiting response... 200 OK\nLength: 19315 (19K) [text/csv]\nSaving to: ‘/tmp/DS1-labels.csv.3’\n\n     0K .......... ........                                   100% 2.36M=0.008s\n\n2019-05-09 11:14:33 (2.36 MB/s) - ‘/tmp/DS1-labels.csv.3’ saved [19315/19315]\n\n:sh: Scheme missing.\n--2019-05-09 11:14:33--  http://wget/\nResolving wget (wget)... failed: Name or service not known.\nwget: unable to resolve host address ‘wget’\n--2019-05-09 11:14:33--  http://www.clustering4ever.org/Datasets/Aggregation/aggregation.csv\nReusing existing connection to www.clustering4ever.org:80.\nHTTP request sent, awaiting response... 200 OK\nLength: 8063 (7.9K) [text/csv]\nSaving to: ‘/tmp/aggregation.csv’\n\n     0K .......                                               100% 1.86M=0.004s\n\n2019-05-09 11:14:34 (1.86 MB/s) - ‘/tmp/aggregation.csv’ saved [8063/8063]\n\n:sh: Scheme missing.\n--2019-05-09 11:14:34--  http://wget/\nResolving wget (wget)... failed: Name or service not known.\nwget: unable to resolve host address ‘wget’\n--2019-05-09 11:14:34--  http://www.clustering4ever.org/Datasets/Aggregation/labels\nReusing existing connection to www.clustering4ever.org:80.\nHTTP request sent, awaiting response... 200 OK\nLength: 1576 (1.5K)\nSaving to: ‘/tmp/labels’\n\n     0K .                                                     100%  293M=0s\n\n2019-05-09 11:14:34 (293 MB/s) - ‘/tmp/labels’ saved [1576/1576]\n\nFINISHED --2019-05-09 11:14:34--\nTotal wall clock time: 1.0s\nDownloaded: 4 files, 100K in 0.4s (229 KB/s)\njava.lang.RuntimeException: Nonzero exit value: 4\n  at scala.sys.package$.error(package.scala:27)\n  at scala.sys.process.ProcessBuilderImpl$AbstractBuilder.slurp(ProcessBuilderImpl.scala:132)\n  at scala.sys.process.ProcessBuilderImpl$AbstractBuilder.$bang$bang(ProcessBuilderImpl.scala:103)\n  ... 65 elided\n"
        }
      ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "C68942FAAFED44D48EABB57163AFEB46"
      },
      "cell_type" : "code",
      "source" : [
        "type SeqType = mutable.ArrayBuffer[Double]\n",
        "val path = \"/tmp/aggregation.csv\"\n",
        "val data = scala.io.Source.fromFile(path).getLines.map( x => mutable.ArrayBuffer(x.split(\",\").map(_.toDouble):_*) ).zipWithIndex\n",
        "  .map{ case (v, id) => EasyClusterizable(id.toLong, ScalarVector(v)) }.toSeq\n",
        "val rdd = sc.parallelize(data)\n",
        "val labelsPath = \"/tmp/labels\""
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "defined type alias SeqType\npath: String = /tmp/aggregation.csv\ndata: Seq[org.clustering4ever.clusterizables.EasyClusterizable[None.type,org.clustering4ever.vectors.ScalarVector[scala.collection.mutable.ArrayBuffer[Double]]]] = Stream(EasyClusterizable(0,Vectorizable(None),ScalarVector(ArrayBuffer(15.55, 28.65)),shapeless.HMap@6bc1d167,Vector()), ?)\nrdd: org.apache.spark.rdd.RDD[org.clustering4ever.clusterizables.EasyClusterizable[None.type,org.clustering4ever.vectors.ScalarVector[scala.collection.mutable.ArrayBuffer[Double]]]] = ParallelCollectionRDD[0] at parallelize at <console>:86\nlabelsPath: String = /tmp/labels\n"
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : ""
          },
          "output_type" : "execute_result",
          "execution_count" : 4,
          "time" : "Took: 1.421s, at 2019-05-09 11:14"
        }
      ]
    },
    {
      "metadata" : {
        "id" : "2AC6EC51B13340A1BA88C605AC6CB7BA"
      },
      "cell_type" : "markdown",
      "source" : "## Gradient Ascent parameters"
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "9A338904F8B8409E8550F6B3D8875667"
      },
      "cell_type" : "code",
      "source" : [
        "val k = 80 // Main Gradient Ascent parameter, the k of knn gradient ascent\n",
        "val k2 = 1 // Optional parameter which determine if studied point has to switch to its knn majority vote neighbor bucket\n",
        "val epsilon = 0.01 // Stopping criteria for Gradient Ascent, every point have to moove less than epsilon in order to stop iteration\n",
        "val maxNumberIter = 20 \n",
        "val bucketLayers = 1 // Neighbor bucket layer take into account during Gradient Ascent, at least 1 is recommended for decent k values, the bigger it is the slower it become\n",
        "val w = 1D // Don't observe any change by changing this value, let it to whatever you want\n",
        "val bucketNumber = 8 // Approximatively DS_Size / 1000 for decent performance, the large buckets are the slower it becomes\n",
        "val propConvStopIter = 1D // Supplementary stopping criteria, stop if propConvStopIter % of data have converged\n",
        "val memoryExpensive = true // Choose for fast or slow computation at some memory cost (building of similarity matrix per bucket per iter or on the fly (more calculus))\n",
        "val persistanceLVL: StorageLevel = StorageLevel.MEMORY_ONLY // Persistance Spark level \n",
        "val dim = 2 // Dim of your dataset\n",
        "val lsh = LDLSH[SeqType](dim, w)"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "k: Int = 80\nk2: Int = 1\nepsilon: Double = 0.01\nmaxNumberIter: Int = 20\nbucketLayers: Int = 1\nw: Double = 1.0\nbucketNumber: Int = 8\npropConvStopIter: Double = 1.0\nmemoryExpensive: Boolean = true\npersistanceLVL: org.apache.spark.storage.StorageLevel = StorageLevel(memory, deserialized, 1 replicas)\ndim: Int = 2\nlsh: org.clustering4ever.hashing.LDLSH[SeqType] = LDLSH(2,1.0)\n"
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : ""
          },
          "output_type" : "execute_result",
          "execution_count" : 5,
          "time" : "Took: 0.938s, at 2019-05-09 11:14"
        }
      ]
    },
    {
      "metadata" : {
        "id" : "F3826FA03FC741D7BA6A10E736817F15"
      },
      "cell_type" : "markdown",
      "source" : "## Epsilon proximity parameters"
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "D1ACA7CD189D47AA958D57A94ECF8B60"
      },
      "cell_type" : "code",
      "source" : [
        "// Main parameter epsilon can be approximate with average distance knn => \"knn:88\" or be expressed directly as a double \"eps:3.67\"\n",
        "val epsilonEpsProx = \"knn:40\"\n",
        "// val epsilonEpsProx = \"eps:2.56\"\n",
        "val classicalMetric = Euclidean[SeqType](false)\n",
        "val bucketNumber = 8 // Number of buckets in LSH, Approximatively DS_Size / 1000 for decent performance, the large buckets are the slower it becomes\n",
        "val bucketLayers = 1 // Neighbor bucket layer take into account during Gradient Ascent, at least 1 is recommended for decent k values, the bigger it is the slower it become\n",
        "val methodChoice = \"bydot:1\" // Fusionning cluster methods, at least X dot have to satisfy fusionning condition with \"bydot:X\", X=1 is greatly recommended\n",
        "val divisionFactor = 1 // Experimental, let it to 1, it is supposed to speedup process on large datasets with bigger values but doesn't affect results\n",
        "val cmin = 0 // Fusion clusters that have less than X elements with their closest cluster, it is in O(c²) with c number of clusters."
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "epsilonEpsProx: String = knn:40\nclassicalMetric: org.clustering4ever.math.distances.scalar.Euclidean[SeqType] = Euclidean distance without squared root applied\nbucketNumber: Int = 8\nbucketLayers: Int = 1\nmethodChoice: String = bydot:1\ndivisionFactor: Int = 1\ncmin: Int = 0\n"
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : ""
          },
          "output_type" : "execute_result",
          "execution_count" : 6,
          "time" : "Took: 0.741s, at 2019-05-09 11:14"
        }
      ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "D3CBF92FF6804C938589ECA9BC5C0D29"
      },
      "cell_type" : "code",
      "source" : [
        "// Theses 3 params have to be here else there is some bugs..., it works more properly on full programm versions\n",
        "val idOriginalVector = 8\n",
        "val idToStoreGAVector = 0\n",
        "val vm = VMapping[Int, ScalarVector[SeqType]]\n",
        "\n",
        "val t0 = System.currentTimeMillis\n",
        "\n",
        "val ascended = GradientAscent.train(rdd, k, epsilon, maxNumberIter, bucketNumber, bucketLayers, k2, propConvStopIter, memoryExpensive,\n",
        "  persistanceLVL, idToStoreGAVector, true)\n",
        "\n",
        "\n",
        "val updatedData = ascended.map( cz => cz.addAlternativeVector(idOriginalVector, cz.v).switchForExistingVectorization(idToStoreGAVector, vm) )\n",
        "\n",
        "val model = EpsilonProximityScalar(\n",
        "  epsilonEpsProx,\n",
        "  methodChoice,\n",
        "  classicalMetric,\n",
        "  bucketNumber,\n",
        "  lsh,\n",
        "  cmin,\n",
        "  bucketLayers,\n",
        "  StorageLevel.MEMORY_ONLY,\n",
        "  divisionFactor\n",
        ").fit(updatedData)\n",
        "\n",
        "val clusterizedRDD = model.obtainInputDataClustering(updatedData)\n",
        "\n",
        "val predLabels = clusterizedRDD.map(_.clusterIDs.head).collect\n",
        "\n",
        "val t1 = System.currentTimeMillis\n",
        "\n",
        "val trueLabels = scala.io.Source.fromFile(labelsPath).getLines.map(_.toInt).toSeq.toArray\n",
        "val targetAndPred = trueLabels.zip(predLabels)\n",
        "\n",
        "(t1 - t0) / 1000D"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "idOriginalVector: Int = 8\nidToStoreGAVector: Int = 0\nvm: org.clustering4ever.shapeless.VMapping[Int,org.clustering4ever.vectors.ScalarVector[SeqType]] = org.clustering4ever.shapeless.VMapping@24ca2c10\nt0: Long = 1557393278748\nascended: org.apache.spark.rdd.RDD[org.clustering4ever.clusterizables.EasyClusterizable[None.type,org.clustering4ever.vectors.ScalarVector[scala.collection.mutable.ArrayBuffer[Double]]]] = MapPartitionsRDD[32] at map at GradientAscent.scala:223\nupdatedData: org.apache.spark.rdd.RDD[org.clustering4ever.clusterizables.EasyClusterizable[None.type,org.clustering4ever.vectors.ScalarVector[SeqType]]] = MapPartitionsRDD[33] at map at <console>:118\nmodel: org.clustering4ever.clustering.epsilonproximity.rdd.EpsilonProximityModelScalar[SeqType,org.clustering4ever.math.distan..."
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : "5.428"
          },
          "output_type" : "execute_result",
          "execution_count" : 7,
          "time" : "Took: 6.874s, at 2019-05-09 11:14"
        }
      ]
    },
    {
      "metadata" : {
        "id" : "88D930FE348941A9866A98C1183A5585"
      },
      "cell_type" : "markdown",
      "source" : "## Plot results if there are less than 25 clusters"
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "EAA60F25842F4783B5952978EB8B319F"
      },
      "cell_type" : "code",
      "source" : [
        "val preViz = clusterizedRDD.map( cz => (cz.clusterIDs.head, cz.v.vector.toArray) ).collect\n",
        "val rawData = clusterizedRDD.map(_.vectorized.get(idOriginalVector)(vm).get.vector.toArray).collect\n",
        "val rawDataConverged = preViz.map(_._2)\n",
        "val clusterIDs = preViz.map(_._1)"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "preViz: Array[(Int, Array[Double])] = Array((5,Array(12.866249999999999, 25.054374999999997)), (5,Array(12.866249999999999, 25.054374999999997)), (5,Array(12.866249999999999, 25.054374999999997)), (5,Array(9.738749999999998, 25.246875)), (5,Array(9.738749999999998, 25.246875)), (5,Array(9.738749999999998, 25.246875)), (5,Array(9.738749999999998, 25.246875)), (5,Array(8.314375000000002, 24.136249999999997)), (5,Array(8.221875, 24.159374999999997)), (5,Array(8.221875, 24.159374999999997)), (5,Array(7.144374999999998, 22.196874999999995)), (6,Array(7.628749999999999, 15.703749999999996)), (5,Array(7.328749999999998, 21.938749999999995)), (6,Array(7.628749999999999, 15.703749999999996)), (5,Array(7.8125, 21.235625)), (5,Array(7.8125, 21.235625)), (5,Array(8.365, 23.965624999999996)), (5,Arr..."
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : ""
          },
          "output_type" : "execute_result",
          "execution_count" : 22,
          "time" : "Took: 0.687s, at 2019-05-09 11:18"
        }
      ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "718FCFEC3936448989F43E2A51BCA8ED"
      },
      "cell_type" : "code",
      "source" : [
        "plot(rawData, clusterIDs, '*', Palette.COLORS)\n",
        "plot(rawDataConverged, clusterIDs, '*', Palette.COLORS)"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "res32: smile.plot.Window = Window(javax.swing.JFrame[frame2,460,37,1000x1000,invalid,layout=java.awt.BorderLayout,title=Smile Plot 4,resizable,normal,defaultCloseOperation=DISPOSE_ON_CLOSE,rootPane=javax.swing.JRootPane[,5,25,990x970,invalid,layout=javax.swing.JRootPane$RootLayout,alignmentX=0.0,alignmentY=0.0,border=,flags=16777673,maximumSize=,minimumSize=,preferredSize=],rootPaneCheckingEnabled=true],smile.plot.PlotCanvas[,0,0,0x0,invalid,layout=java.awt.BorderLayout,alignmentX=0.0,alignmentY=0.0,border=,flags=9,maximumSize=,minimumSize=,preferredSize=])\n"
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : "Window(javax.swing.JFrame[frame2,460,37,1000x1000,layout=java.awt.BorderLayout,title=Smile Plot 4,resizable,normal,defaultCloseOperation=DISPOSE_ON_CLOSE,rootPane=javax.swing.JRootPane[,0,37,1000x963,layout=javax.swing.JRootPane$RootLayout,alignmentX=0.0,alignmentY=0.0,border=,flags=16777675,maximumSize=,minimumSize=,preferredSize=],rootPaneCheckingEnabled=true],smile.plot.PlotCanvas[,0,0,1000x963,layout=java.awt.BorderLayout,alignmentX=0.0,alignmentY=0.0,border=,flags=11,maximumSize=,minimumSize=,preferredSize=])"
          },
          "output_type" : "execute_result",
          "execution_count" : 24,
          "time" : "Took: 0.954s, at 2019-05-09 11:18"
        }
      ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "A00E20D38F3D4E9A87F6E12FB055C669"
      },
      "cell_type" : "code",
      "source" : [
        "val mei = new MultiExternalIndicesLocal(targetAndPred)"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "mei: org.clustering4ever.clustering.indices.MultiExternalIndicesLocal = MultiExternalIndicesLocal(WrappedArray((2,5), (2,5), (2,5), (2,5), (2,5), (2,5), (2,5), (2,5), (2,5), (2,5), (2,5), (2,6), (2,5), (2,6), (2,5), (2,5), (2,5), (2,5), (2,5), (2,5), (2,5), (2,5), (2,7), (2,7), (2,7), (2,7), (2,7), (2,7), (2,7), (2,7), (2,7), (2,7), (2,7), (2,7), (2,7), (2,7), (2,7), (2,7), (2,7), (2,7), (2,7), (2,7), (2,7), (2,7), (2,7), (2,7), (2,7), (2,7), (2,7), (2,7), (2,7), (2,7), (2,7), (2,7), (2,7), (2,7), (2,7), (2,7), (2,7), (2,7), (2,3), (2,3), (2,3), (2,3), (2,3), (2,3), (2,3), (2,3), (2,3), (2,3), (2,3), (2,3), (2,3), (2,0), (2,0), (2,0), (2,0), (2,0), (2,0), (2,0), (2,0), (2,0), (2,0), (2,0), (2,0), (2,0), (2,0), (2,0), (2,0), (2,2), (2,2), (2,2), (2,0), (2,2), (2,0), (2,7), (2,7), (2,7), ..."
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : ""
          },
          "output_type" : "execute_result",
          "execution_count" : 9,
          "time" : "Took: 1.093s, at 2019-05-09 11:14"
        }
      ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "9DF25C93E2984A138B8F05710A6C874E"
      },
      "cell_type" : "code",
      "source" : [
        "(\n",
        "  mei.nmiSQRT,\n",
        "  mei.f1,\n",
        "  mei.rand,\n",
        "  mei.arand\n",
        ")"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "res34: (Double, Double, Double, Double) = (0.06054073807627623,0.25799546961688713,0.6355400899128606,0.020905379631695573)\n"
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : "(0.06054073807627623,0.25799546961688713,0.6355400899128606,0.020905379631695573)"
          },
          "output_type" : "execute_result",
          "execution_count" : 25,
          "time" : "Took: 0.496s, at 2019-05-09 11:20"
        }
      ]
    }
  ],
  "nbformat" : 4
}